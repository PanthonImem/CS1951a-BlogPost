{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Extracting Text from Each Page.ipynb","version":"0.3.2","provenance":[{"file_id":"1D1014mKlRTiJBNfuYXYTUx6UCGps-nrC","timestamp":1550690793567}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"4SPeMUVSWOAu","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy\n","from bs4 import BeautifulSoup, Comment\n","import requests\n","import sqlite3\n","import json\n","import os\n","import urllib\n","import re"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S9kmw9MtWEUl","colab_type":"code","outputId":"eeba63b5-1b09-406e-ae06-fc11f8a6cf25","executionInfo":{"status":"error","timestamp":1550693731337,"user_tz":300,"elapsed":552,"user":{"displayName":"Panthon Imemkamon","photoUrl":"","userId":"07599040044784257813"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"cell_type":"code","source":["with open('names.json', 'r') as f:\n","    names = json.load(f)\n","\n","S = requests.Session()\n","\n","URL = \"https://en.wikipedia.org/w/api.php\"\n","\n","plain_text = {}\n","n=0\n","\n","# INTERESTING PROPERTIES\n","# length of each page -- from 'length' in 'info' prop\n","# number of categories the page falls into -- count 'title' from \"categories\"\n","# categories -- from \"categories\"\n","# number of links in each page -- count 'title' in \"links\"\n","# number of interlanguage links from each page -- count 'lang' in \"langlinks\"\n","\n","for counter, e in enumerate(names):\n","  # info =  display basic information about the given page\n","  # categories = list all categories the pages belong to\n","  # links = returns all links from the given pages\n","  # linkshere: find all pages that link to the given pages\n","  # langlinks: returns all interlanguage links from the given pages\n","  title = e[0]\n","  NORMAL_PROP_PARAMS = {\n","      \"action\": \"query\",\n","      \"format\": \"json\",\n","      \"titles\": title,\n","      \"prop\": \"info|categories|links|linkshere|langlinks\"\n","  }\n","\n","  # extract plain text from the first paragraph of the page\n","  # https://stackoverflow.com/questions/4452102/how-to-get-plain-text-out-of-wikipedia\n","  PLAIN_TEXT_PARAMS = {\n","      \"action\": \"query\",\n","      \"format\": \"json\",\n","      \"titles\": title,\n","      'prop': 'extracts',\n","      'exintro': True,\n","      'explaintext': True,\n","  }\n","\n","\n","  # Nine: I tried looking at categoryinfo prop and it did not give much info \n","  # about each page (aka not many pages have the info)\n","\n","  r = S.get(url=URL, params=PLAIN_TEXT_PARAMS)\n","  response = r.json()\n","  page = next(iter(response['query']['pages'].values()))\n","  plain_text[title] = page['extract']\n","\n","\n","with open('plain_text.json', 'w') as fp:\n","    json.dump(plain_text, fp)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-ec59b41ec216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'names.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'names.json'"]}]}]}