{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "import threading\n",
    "import string\n",
    "import functools\n",
    "import collections\n",
    "import numpy as np\n",
    "from nltk.corpus import words\n",
    "import spacy.tokenizer, spacy.lemmatizer\n",
    "import urllib.parse\n",
    "import nltk\n",
    "\n",
    "#eng_line = re.sub('([.,!?():;])', r' \\1 ', eng_line)\n",
    "#eng_line = re.sub('\\s{2,}', ' ', eng_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/mafuangimemkamon/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "common_words = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pages.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<NUM> poom <NUM> oo o<NUM>o'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"123 poom 1 oo o1o\"\n",
    "sections = re.split(\"===* .* ===*\", text)\n",
    "    return [token.lemma_ \n",
    "                for token in nlp(sections[0]) \n",
    "                if token.is_alpha \n",
    "                and not token.is_stop \n",
    "                and token.lemma_ not in {'-PRON-', \"the\", \"a\", \"an\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "for i in range(len(keys)):\n",
    "    if(i%500==0):\n",
    "        print(i)\n",
    "    key = keys[i]\n",
    "    text = data[key][0]\n",
    "    sections = re.split(\"===* .* ===*\", text)\n",
    "\n",
    "    text = ['UNK' if word.pos_ == 'PROPN' else str(word).lower() for word in nlp(sections[0]) ] \n",
    "    \n",
    "    text = ' '.join([str(i) for i in text])\n",
    "    \n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' '+punctuation)\n",
    "    text = \"NUM\".join(re.split(\"[0-9][0-9]*\", text))\n",
    "    text = text + '</stop>'\n",
    "    while '  ' in text:\n",
    "        text = text.replace('  ', ' ')\n",
    "    #print(text)\n",
    "    ls.append(text)\n",
    "print(ls)\n",
    "    #print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cleaned_gans_data.json', 'wb') as f:\n",
    "    test = json.dumps(ls)\n",
    "    f.write(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK UNK UNK ( ) is an english singer , songwriter and television personality . he is known as a member of the boy band one UNK . UNK began his career as an actor , appearing in UNK drama film if i had you and the UNK drama UNK UNK . in NUM , he became a member of one UNK after being eliminated as a solo contestant on the british music competition series the UNK UNK . one UNK has since released five albums , embarked on four world tours , and won several awards , becoming one of most successful musical groups of all time . \n",
      " \" just hold on \" was released as UNK 's debut single as a solo artist in UNK NUM , it peaked at number two on the UNK UNK UNK and was certified gold in both the UNK and UNK . in NUM , UNK released \" back to you \" with american singer UNK UNK and \" UNK UNK NUM , UNK was signed as a footballer by UNK UNK of the UNK UNK UNK on a non - contract basis . the same year he also formed his own record label , UNK UNK , as an imprint of one UNK 's label UNK . he appeared on UNK 's NUM list of the most influential people in the UNK . \n",
      "\n",
      "\n",
      "</stop>\n"
     ]
    }
   ],
   "source": [
    "print(ls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
