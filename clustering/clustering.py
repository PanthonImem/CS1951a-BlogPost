# -*- coding: utf-8 -*-
"""word detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O_9wWh9qeu4f2VnyMMn8ngXyjBuBcCVz
"""

from google.colab import drive
drive.mount('/content/gdrive')

cd '/content/gdrive/My Drive/CS1951A final/'

!ls

import pandas as pd
import numpy as np
import json
import os
from collections import Counter
import random
import matplotlib.pyplot as plt

from gensim.models.doc2vec import Doc2Vec, TaggedDocument

from sklearn.cluster import KMeans, SpectralClustering
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
from sklearn.metrics import accuracy_score
from sklearn.feature_extraction.text import CountVectorizer

def sort_dict(mydict):
    for k, v in mydict.items():
        if v is None:
            mydict[k] = 0
    return sorted(mydict.items(), key=lambda k: k[1], reverse=True)

text = json.load(open('lemmatized-tokenized.json'))

career = Counter()
person2career = {}
none = []
for person in text:
    cur = Counter()
    cur['none'] = 0
    for word in text[person]:
        if word in {'actor','actress','film','television','golden','oscar','comedian','show','role','character','host','cast','serie'}:
            cur['actor'] +=1
        if word in {'footballer','football', 'fifa','player','basketball','cup','olympic','wwe','wrestler','team','league','match','score','medal','medalist','boxer','champion','championship'}: 
            cur['sports'] += 1
        if word in {'singer','rapper','musician','album','release','studio','songwriter','music','label','debut','single'}: 
            cur['singers'] += 1
        if word in {'politician','candidate','politic','republican','democrat','campaign','goverment','govern','election','policy','party','governor','president'}:
            cur['politics'] += 1
        if word in {'chairman','ceo','entrepreneur','business','found','billion','heiress','founder','executive','investor','businessman','businesswoman','chief'}:
            cur['business'] += 1
        if word in {'queen','king','princess','prince','empress','monarch','emperor','empire'}:
            cur['royalties'] += 1
        
    person2career[person] = sort_dict(cur)[0][0]
    if person2career[person] is 'none':
        none.append(person)
    career[person2career[person]] += 1
 
print(career)

from sklearn import preprocessing

le = preprocessing.LabelEncoder()
labels = le.fit_transform(list(person2career.values()))

doc_ids = np.array(list(text.keys()))

def doc2vec(data, doc_ids, embedding_size=50, window_size=2, min_count=1, workers=4):
    docs = list(data.values())
    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(docs)]
    model = Doc2Vec(documents, 
                    vector_size=embedding_size, 
                    window=window_size, 
                    min_count=min_count, 
                    workers=workers)
    return np.array([model.infer_vector(data[key]) for key in doc_ids])

def bags_of_words(data, doc_ids):
    docs = [' '.join(data[key]) for key in doc_ids]
    model = CountVectorizer().fit_transform(docs)
    counts = model.toarray()
    return counts / np.linalg.norm(counts)

def kmeanscluster(vectors, doc_ids, id2doc, n_clusters=10):
    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(vectors)

    doc_ids_clusters, doc_clusters, variances = [], [], []
    for i in range(n_clusters):
        doc_ids_clusters.append(doc_ids[kmeans.labels_ == i])
        doc_clusters.append([id2doc[key] for key in doc_ids[kmeans.labels_ == i]])
        variances.append(variance(vectors[kmeans.labels_ == i]))
    
    print('cluster variance:', variances)
    print('cluster size:', [len(c) for c in doc_clusters])
    
    return doc_ids_clusters, doc_clusters, list(kmeans.labels_)

def tfidf(data, doc_ids, use_idf=True):
    docs = [' '.join(data[key]) for key in doc_ids]
    model = TfidfVectorizer(use_idf=use_idf).fit_transform(docs)
    counts = model.toarray()
    return counts / np.linalg.norm(counts)

def variance(vectors):
    return np.mean(np.var(vectors, axis=0))

# https://www.datacamp.com/community/tutorials/wordcloud-python
def make_wordcloud(docs):
    wordcloud = WordCloud().generate(' '.join([token for d in docs for token in d]))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    plt.show()
    
def show_wordclouds_kmeanscluster(vecs, doc_ids, data, n_clusters):
    id_clusters, doc_clusters, predictions = kmeanscluster(vecs, doc_ids, data, n_clusters=n_clusters)
    for i in range(n_clusters):
        print('Pages in cluster:', [x[6:] for x in id_clusters[i][:10]])
        make_wordcloud(doc_clusters[i])
    return predictions

def spectralcluster(vectors, doc_ids, id2doc, n_clusters=10):
    sepctralclustering = SpectralClustering(
        n_clusters=n_clusters, 
         assign_labels="discretize",
        random_state=0
    ).fit(vectors)

    doc_ids_clusters, doc_clusters, variances = [], [], []
    for i in range(n_clusters):
        doc_ids_clusters.append(doc_ids[sepctralclustering .labels_ == i])
        doc_clusters.append([id2doc[key] for key in doc_ids[sepctralclustering .labels_ == i]])
        variances.append(variance(vectors[sepctralclustering .labels_ == i]))
    
    print('cluster variance:', variances)
    print('cluster size:', [len(c) for c in doc_clusters])
    
    return doc_ids_clusters, doc_clusters, list(sepctralclustering .labels_)

def show_wordclouds_spectralcluster(vecs, doc_ids, data, n_clusters):
    id_clusters, doc_clusters, predictions = spectralcluster(vecs, doc_ids, data, n_clusters=n_clusters)
    for i in range(n_clusters):
        print('Pages in cluster:', [x[6:] for x in id_clusters[i][:10]])
        make_wordcloud(doc_clusters[i])
    return predictions

n_clusters = 10

# doc2vec
d2v_vecs = doc2vec(text, doc_ids)
predictions = show_wordclouds_spectralcluster(d2v_vecs, doc_ids, text, n_clusters)

correct = Counter()
wrong = Counter()
total = Counter()
l = list(le.classes_)

for i,p in enumerate(predictions):
    if p in {0, 2, 9}: #actor
        if labels[i] == 0:
            correct[l[0]] += 1
        elif labels[i] != 2:
            wrong[l[0]] += 1
        total[l[0]] += 1
    if p == 6: #business
        if labels[i] == 1:
            correct[l[1]] += 1
        elif labels[i] != 2:
            wrong[l[1]] += 1
        total[l[1]] += 1
    if p == 3: #politics
        if labels[i] == 3:
            correct[l[3]] += 1
        elif labels[i] != 2:
            wrong[l[3]] += 1 
        total[l[3]] += 1
    if p == 8: #singers
        if labels[i] == 5:
            correct[l[5]] += 1
        elif labels[i] != 2:
            wrong[l[5]] += 1  
        total[l[5]] += 1
    if p in {1,5}: #royalties
        if labels[i] == 4:
            correct[l[4]] += 1
        elif labels[i] != 2:
            wrong[l[4]] += 1  
        total[l[4]] += 1
    if p in {4,7}: #sports
        if labels[i] == 6:
            correct[l[6]] += 1
        elif labels[i] != 2:
            wrong[l[6]] += 1
        total[l[6]] += 1
print('Correct:', correct)
print('Wrong:', wrong)
print('Total accuracy: ', (sum(correct.values())/10000))
for c in l:
    if c != 'none':
        print('accuracy for %s: %.4f' % (c, correct[c]/total[c]))

n_clusters = 10

# doc2vec
bow_vecs = bags_of_words(text, doc_ids)
predictions = show_wordclouds_spectralcluster(bow_vecs, doc_ids, text, n_clusters)

correct = Counter()
wrong = Counter()
total = Counter()
l = list(le.classes_)

for i,p in enumerate(predictions):
    if p in {1, 4, 8,9}: #actor
        if labels[i] == 0:
            correct[l[0]] += 1
        elif labels[i] != 2:
            wrong[l[0]] += 1
        total[l[0]] += 1
    if p == 0: #other
        if labels[i] in {1, 4, 2}:
            correct[l[labels[i]]] += 1
        else:
            wrong[l[labels[i]]] += 1
        total[l[labels[i]]] += 1
    if p == 3: #politics
        if labels[i] == 3:
            correct[l[3]] += 1
        elif labels[i] != 2:
            wrong[l[3]] += 1 
        total[l[3]] += 1
    if p == 7: #singers
        if labels[i] == 5:
            correct[l[5]] += 1
        elif labels[i] != 2:
            wrong[l[5]] += 1  
        total[l[5]] += 1
    if p in {2,5,6}: #sports
        if labels[i] == 6:
            correct[l[6]] += 1
        elif labels[i] != 2:
            wrong[l[6]] += 1
        total[l[6]] += 1
print('Correct:', correct)
print('Wrong:', wrong)
print('Total accuracy: ', (sum(correct.values())/10000))
for c in l:
    if c != 'none':
        print('accuracy within the cluster for %s: %.4f' % (c, correct[c]/total[c]))
        print('accuracy with the true labels for %s: %.4f' % (c, correct[c]/career[c]))